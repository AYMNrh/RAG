{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62601663",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963f2620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.14-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\cytech student\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.29-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.3-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.30 (from langchain)\n",
      "  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.37 (from langchain)\n",
      "  Downloading langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.40-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Using cached pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\cytech student\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cytech student\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\cytech student\\appdata\\roaming\\python\\python311\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.37->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.0-cp311-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 50.7/50.7 kB 880.1 kB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic<3,>=1->langchain)\n",
      "  Using cached pydantic_core-2.16.3-cp311-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
      "   ---------------------------------------- 0.0/812.8 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 92.2/812.8 kB 1.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 194.6/812.8 kB 2.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 286.7/812.8 kB 2.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 389.1/812.8 kB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 491.5/812.8 kB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 624.6/812.8 kB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 747.5/812.8 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 812.8/812.8 kB 2.2 MB/s eta 0:00:00\n",
      "Using cached aiohttp-3.9.3-cp311-cp311-win_amd64.whl (365 kB)\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/1.9 MB 3.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.9 MB 3.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/1.9 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/1.9 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.3/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.5/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.40-py3-none-any.whl (276 kB)\n",
      "   ---------------------------------------- 0.0/276.8 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 143.4/276.8 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 276.8/276.8 kB 2.8 MB/s eta 0:00:00\n",
      "Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.40-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB 2.5 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "Using cached pydantic_core-2.16.3-cp311-none-win_amd64.whl (1.9 MB)\n",
      "Using cached SQLAlchemy-2.0.29-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "Using cached greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.0-cp311-none-win_amd64.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.2/139.2 kB 4.2 MB/s eta 0:00:00\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "Installing collected packages: typing-inspect, tenacity, pydantic-core, packaging, orjson, multidict, jsonpatch, greenlet, frozenlist, annotated-types, yarl, SQLAlchemy, pydantic, marshmallow, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.0\n",
      "    Uninstalling packaging-23.0:\n",
      "      Successfully uninstalled packaging-23.0\n",
      "Successfully installed SQLAlchemy-2.0.29 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 dataclasses-json-0.6.4 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.1.14 langchain-community-0.0.31 langchain-core-0.1.40 langchain-text-splitters-0.0.1 langsmith-0.1.40 marshmallow-3.21.1 multidict-6.0.5 orjson-3.10.0 packaging-23.2 pydantic-2.6.4 pydantic-core-2.16.3 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n",
      "Collecting gpt4all\n",
      "  Downloading gpt4all-2.4.0-py3-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\cytech student\\appdata\\roaming\\python\\python311\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gpt4all) (4.64.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->gpt4all) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->gpt4all) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->gpt4all) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Downloading gpt4all-2.4.0-py3-none-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/6.3 MB 1.7 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.2/6.3 MB 2.4 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/6.3 MB 3.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.6/6.3 MB 3.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.7/6.3 MB 3.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.0/6.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.0/6.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.2/6.3 MB 3.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.4/6.3 MB 3.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.5/6.3 MB 3.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.5/6.3 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.7/6.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.9/6.3 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.0/6.3 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.1/6.3 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.2/6.3 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.4/6.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.5/6.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.8/6.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.9/6.3 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.0/6.3 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.2/6.3 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.3/6.3 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.4/6.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.6/6.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.7/6.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.9/6.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.0/6.3 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.3/6.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.8/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.1/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.3/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.4/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.6/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.8/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.3 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.1/6.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: gpt4all\n",
      "Successfully installed gpt4all-2.4.0\n",
      "Collecting qdrant-client\n",
      "  Downloading qdrant_client-1.8.2-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from qdrant-client) (1.51.3)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client)\n",
      "  Downloading grpcio_tools-1.62.1-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting httpx>=0.20.0 (from httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from qdrant-client) (1.23.5)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from qdrant-client) (2.6.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from qdrant-client) (1.26.14)\n",
      "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client) (4.22.0)\n",
      "Collecting grpcio>=1.41.0 (from qdrant-client)\n",
      "  Using cached grpcio-1.62.1-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client) (65.5.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\cytech student\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2022.12.7)\n",
      "Collecting httpcore==1.* (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\cytech student\\appdata\\roaming\\python\\python311\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\cytech student\\appdata\\roaming\\python\\python311\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client) (305)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (4.10.0)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading qdrant_client-1.8.2-py3-none-any.whl (223 kB)\n",
      "   ---------------------------------------- 0.0/223.2 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 30.7/223.2 kB ? eta -:--:--\n",
      "   -------------------------- ----------- 153.6/223.2 kB 510.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 223.2/223.2 kB 649.3 kB/s eta 0:00:00\n",
      "Downloading grpcio_tools-1.62.1-cp311-cp311-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.1/1.1 MB 1.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.2/1.1 MB 1.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.3/1.1 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.3/1.1 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.4/1.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.5/1.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.6/1.1 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.6/1.1 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.7/1.1 MB 948.7 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 0.8/1.1 MB 957.1 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.1 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.9/1.1 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.0/1.1 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 1.1 MB/s eta 0:00:00\n",
      "Using cached grpcio-1.62.1-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 71.7/77.9 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 77.9/77.9 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: portalocker, hyperframe, hpack, h11, grpcio, httpcore, h2, grpcio-tools, httpx, qdrant-client\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.51.3\n",
      "    Uninstalling grpcio-1.51.3:\n",
      "      Successfully uninstalled grpcio-1.51.3\n",
      "Successfully installed grpcio-1.62.1 grpcio-tools-1.62.1 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hyperframe-6.0.1 portalocker-2.8.2 qdrant-client-1.8.2\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.39.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\cytech student\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cytech student\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\cytech student\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Using cached sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install gpt4all\n",
    "!pip install qdrant-client\n",
    "!pip install sentence-transformers\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd892ac-f5ea-4e04-ae68-9fa316965582",
   "metadata": {},
   "source": [
    "## Set huggingface cache home (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b1d64b-12f4-417a-82de-3faf9e69ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_dir=\"huggingface/\"\n",
    "os.environ[\"HF_HOME\"] = cache_dir\n",
    "\n",
    "model_dir = \"H:\\\\RAGT\\\\Financial-RAG-GPU-less-Mistral-Langchain\\\\models\\\\mistral-7b-instruct-v0.1.Q4_0.gguf\"\n",
    "os.environ[\"MODEL\"] = model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339c30b-240d-4a30-a699-61fed6e10f4e",
   "metadata": {},
   "source": [
    "## Check Device (assuming no GPU is available)\n",
    "\n",
    "I have a GPU available but for you it will print \"cpu\" if you don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4564a8e1-57bb-4ffc-996c-b9d27999b53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5824f34-3014-4425-b019-72298af53f43",
   "metadata": {},
   "source": [
    "## Enable to see Logs while running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b9c154-9ae8-4084-b2b6-1fcb9f8a7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404518cd-0bad-40be-94b9-f47190ffbe75",
   "metadata": {},
   "source": [
    "## Load Data, preprocessing and Creating Qdrant Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0799c19-bb4f-4d04-872a-9d21c72a5f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 14:57:40,068 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n",
      "2024-04-05 14:57:40,079 - urllib3.connectionpool - DEBUG - Resetting dropped connection: huggingface.co\n",
      "2024-04-05 14:57:40,490 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/modules.json HTTP/1.1\" 200 0\n",
      "2024-04-05 14:57:40,646 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/config_sentence_transformers.json HTTP/1.1\" 200 0\n",
      "2024-04-05 14:57:40,789 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/README.md HTTP/1.1\" 200 0\n",
      "2024-04-05 14:57:40,929 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/modules.json HTTP/1.1\" 200 0\n",
      "2024-04-05 14:57:41,078 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/sentence_bert_config.json HTTP/1.1\" 200 0\n",
      "2024-04-05 14:57:41,216 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-04-05 14:57:47,986 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"HEAD /BAAI/bge-large-en-v1.5/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2024-04-05 14:57:48,968 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 \"GET /api/models/BAAI/bge-large-en-v1.5/revision/main HTTP/1.1\" 200 147283\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text_lower = text.lower()\n",
    "    text_no_punctuation = re.sub(r'[^\\w\\s\\$\\%\\.\\,\\\"\\'\\!\\?\\(\\)]', '', text_lower)\n",
    "    text_normalized_tabs = re.sub(r'(\\t)+', '', text_no_punctuation)\n",
    "    return text_normalized_tabs\n",
    "\n",
    "# loader = PyPDFLoader(\"data/msft_annual_2023_report.pdf\")\n",
    "loader = PyPDFLoader(\"data/Recipes.pdf\")\n",
    "# loader = TextLoader(sample_texts)\n",
    "# loader = WebBaseLoader(\"https://cleartax.in/s/top-performing-nps-schemes\")\n",
    "documents = loader.load()\n",
    "for x in range(len(documents)):\n",
    "    # do preprocessing\n",
    "    documents[x].page_content=preprocess_text(documents[x].page_content)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0,separator=\"\\n\")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\", \n",
    "                                   model_kwargs = {'device': \"cpu\"})  # forcefully setting device as cpu\n",
    "qdrant = Qdrant.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    location=\":memory:\",  # Local mode with in-memory storage only\n",
    "    collection_name=\"msft_data\",\n",
    "    force_recreate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0718369-0b21-495e-97f7-b9487a3b9197",
   "metadata": {},
   "source": [
    "## Run if not able to download model using GPT4All directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1574c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download model\n",
    "\n",
    "# !mkdir models\n",
    "# !wget https://gpt4all.io/models/gguf/mistral-7b-instruct-v0.1.Q4_0.gguf -O models/mistral-7b-instruct-v0.1.Q4_0.gguf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb1a0c-ab69-4204-9895-6c217a7738c7",
   "metadata": {},
   "source": [
    "## Directly calling GPT4All module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a199e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(model_name=\"H:\\RAGT\\Financial-RAG-GPU-less-Mistral-Langchain\\models\\mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
    "                             n_threads = 8,\n",
    "                             allow_download=False) # set allow_download as true to fetch it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d422d667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Paris, France\n",
      "\n",
      "The Eiffel Tower is an iconic landmark located in Paris,\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Eiffel tower location:\"\n",
    "print(model.generate(prompt, max_tokens=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa975f-e5b3-4af2-840e-bc644dea42ae",
   "metadata": {},
   "source": [
    "## Creating prompts, tuning parameters and creating Chain using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "575f9508-a594-4572-8210-90c7de877707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_community.llms import GPT4All\n",
    "\n",
    "# template = '''[INST]: You are a financial expert analyst bot, below presents a context from which the a question will be asked, give your valuable insights as well.[\\INST]\\n\n",
    "# Context: {context}.\\n\n",
    "# Question: {question}\\n\n",
    "# Answer: '''\n",
    "template = '''[INST]: You are a chef with extensive knowledge of various recipes. Based on the context provided, which could either be specific ingredients the user has on hand or a type of dish the user desires, offer a suitable recipe that matches the request.[\\INST]\\n\n",
    "# As a chef renowned for your vast repertoire of recipes, utilize the provided context to craft a recipe. Whether the inquiry involves specific ingredients available to the user or a particular dish they're craving, draw upon your culinary expertise to recommend a recipe that aligns with their needs.\n",
    "Context: {context}.\\n\n",
    "Question: {question}\\n\n",
    "Answer: '''\n",
    "rag_prompt = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
    "\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "llm = GPT4All(\n",
    "            model=\"H:\\RAGT\\Financial-RAG-GPU-less-Mistral-Langchain\\models\\mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
    "            max_tokens=50,\n",
    "            n_threads=8, \n",
    "            temp=0.3,\n",
    "            top_p=0.2,\n",
    "            top_k=40,\n",
    "            n_batch=8,\n",
    "            seed=100,\n",
    "            allow_download=False,  # Prevent downloading\n",
    "            verbose=True)\n",
    "\n",
    "llm_chain = LLMChain(prompt=rag_prompt, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d56e21d-333f-4c16-97a8-abfc1f91f148",
   "metadata": {},
   "source": [
    "## Define format_docs for formatting context candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f09e379-caed-41c1-9c2d-b40c783623ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(query):\n",
    "    found_docs = qdrant.similarity_search_with_score(query,k=1)\n",
    "    return \"\\n\\n\".join(doc[0].page_content for doc in found_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e0014-39cd-4f45-9ec3-3887036dd03e",
   "metadata": {},
   "source": [
    "## Run Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c737ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]: You are a chef with extensive knowledge of various recipes. Based on the context provided, which could either be specific ingredients the user has on hand or a type of dish the user desires, offer a suitable recipe that matches the request.[\\INST]\n",
      "\n",
      "Context: The user has chicken, tomatoes, and rice available and is looking for a recipe that uses these ingredients..\n",
      "\n",
      "Question: What can I make with chicken, tomatoes, and rice?\n",
      "\n",
      "Answer: \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function LLModel._prompt_callback at 0x0000028290CE2980>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\CYTech Student\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gpt4all\\_pyllmodel.py\", line 526, in _prompt_callback\n",
      "    @staticmethod\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "One option could be to make Chicken Fried Rice. Here's the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup uncooked white rice\n",
      "- 2 cups water\n",
      "- Salt\n",
      "- 1 tablespoon vegetable oil\n",
      "- 1 pound boneless, skinless chicken breast, cut into bite-sized pieces\n",
      "- 2 medium tomatoes, diced\n",
      "- 3 green onions, sliced\n",
      "- Soy sauce (optional)\n",
      "\n",
      "Instructions:\n",
      "1. In a medium saucepan, bring water to a boil over high heat. Add rice and salt, stirring occasionally.\n",
      "2. Reduce the heat to low, cover, and simmer for 18-20 minutes or until the rice is cooked through and the water has been absorbed.\n",
      "3. In a large skillet, heat oil over medium-high heat. Add chicken and cook until browned on all sides, about 5-7 minutes.\n",
      "4. Add tomatoes and green onions to the skillet with the chicken. Cook for another 2-3 minutes or until the vegetables are tender.\n",
      "5. Stir in the cooked rice\n",
      "CPU times: total: 2h 24min 43s\n",
      "Wall time: 56min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"What can I make with chicken, tomatoes, and rice?\"\n",
    "context = \"The user has chicken, tomatoes, and rice available and is looking for a recipe that uses these ingredients.\"\n",
    "resp = llm_chain.invoke(\n",
    "    input={\"question\": query,\n",
    "           \"context\": context\n",
    "          }\n",
    ")\n",
    "print(resp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af5f6ce-ae34-40a9-9824-e1778812768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]: You are a financial expert analyst bot, below presents a context from which the a question will be asked, give your valuable insights as well.[\\INST]\n",
      "\n",
      "Context: and selling our other products and service s and income taxes.  \n",
      "highlights from fiscal year 2023 compared with fiscal year 2022 included  \n",
      " microsoft cloud revenue increased 22% to $111.6  billion.  \n",
      " office commercial products and cloud services revenue increased 10% driven by office 365 commercial \n",
      "growth of 13%.  \n",
      " office consumer products and cloud services revenue increased 2% and microsoft 365 consumer subscribers \n",
      "increased to 67.0  million.  \n",
      " linkedin revenue increased 10%.  \n",
      " dynamics products and cloud services revenue increased 16% driven by dynamics 365 growth of 24%.  \n",
      " server products and cloud services revenue increased 19% driven by azure and other cloud services growth \n",
      "of 29%.  \n",
      " windows original equipment manufacturer licensing (windows oem) revenue decreased 25%.  \n",
      " devices revenue decreased 24%.  \n",
      " windows commercial products and cloud services revenue increased 5%.  \n",
      " xbox content and services revenue decreased 3%..\n",
      "\n",
      "Question: who were the top performers in 2023 for microsoft?\n",
      "\n",
      "Answer: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "1. Microsoft Cloud Revenue - Increased by 22% to $111.6 billion, which is a significant growth compared to the previous year.\n",
      "2. Office Commercial Products and Cloud Services Revenue - Increased by 10%, driven by the growth of Office 365 commercial subscribers.\n",
      "3. LinkedIn Revenue - Increased by 10% in fiscal year 2023, which is a positive sign for Microsoft's overall performance.\n",
      "4. Dynamics Products and Cloud Services Revenue - Increased by 16%, driven by the growth of Dynamics 365 products.\n",
      "5. Server Products and Cloud Services Revenue - Increased by 19%, driven by the growth of Azure and other cloud services.\n",
      "CPU times: total: 2h 40min 14s\n",
      "Wall time: 1h 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"who were the top performers in 2023 for microsoft?\"\n",
    "resp = llm_chain.invoke(\n",
    "    input={\"question\":query,\n",
    "           \"context\": format_docs(query)\n",
    "          }\n",
    ")\n",
    "print(resp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc03de8-75d2-4320-a2ca-f601d4b5473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]: You are a financial expert analyst bot, below presents a context from which the a question will be asked, give your valuable insights as well.[\\INST]\n",
      "\n",
      "Context: and selling our other products and service s and income taxes.  \n",
      "highlights from fiscal year 2023 compared with fiscal year 2022 included  \n",
      " microsoft cloud revenue increased 22% to $111.6  billion.  \n",
      " office commercial products and cloud services revenue increased 10% driven by office 365 commercial \n",
      "growth of 13%.  \n",
      " office consumer products and cloud services revenue increased 2% and microsoft 365 consumer subscribers \n",
      "increased to 67.0  million.  \n",
      " linkedin revenue increased 10%.  \n",
      " dynamics products and cloud services revenue increased 16% driven by dynamics 365 growth of 24%.  \n",
      " server products and cloud services revenue increased 19% driven by azure and other cloud services growth \n",
      "of 29%.  \n",
      " windows original equipment manufacturer licensing (windows oem) revenue decreased 25%.  \n",
      " devices revenue decreased 24%.  \n",
      " windows commercial products and cloud services revenue increased 5%.  \n",
      " xbox content and services revenue decreased 3%..\n",
      "\n",
      "Question: who were the worst performers in 2023 for microsoft?\n",
      "\n",
      "Answer: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "1. Windows OEM licensing revenue decreased by 25%, indicating that Microsoft's traditional business model of selling licenses to hardware manufacturers is not as profitable as it used to be.\n",
      "2. Devices revenue decreased by 24%, suggesting that the demand for physical devices such as laptops and tablets may be declining, or that there are other factors affecting this market segment.\n",
      "3. Xbox content and services revenue decreased by 3%, indicating that Microsoft's gaming business is not performing as well as expected.\n",
      "CPU times: total: 3min 52s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"who were the worst performers in 2023 for microsoft?\"\n",
    "resp = llm_chain.invoke(\n",
    "    input={\"question\":query,\n",
    "           \"context\": format_docs(query)\n",
    "          }\n",
    ")\n",
    "print(resp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a8ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]: You are a financial expert analyst bot, below presents a context from which the a question will be asked, give your valuable insights as well.[\\INST]\n",
      "\n",
      "Context: year ended june  30, 2023  2022  2021  \n",
      "        \n",
      "united states (a) $ 106,744   $ 100,218   $ 83,953   \n",
      "other countries   105,171    98,052    84,135         \n",
      "total  $  211,915   $  198,270   $  168,088           \n",
      "(a) includes billings to oems and certain multinational organizations because of the nature of these businesses and the \n",
      "impracticability of determining the geographic source of the revenue.  \n",
      "revenue, classified by significant product and service offerings, was as follows  \n",
      "  \n",
      "(in millions)          \n",
      "        \n",
      "year ended june  30, 2023  2022  2021  \n",
      "        \n",
      "server products and cloud services  $ 79,970   $ 67,350   $ 52,589   \n",
      "office products and cloud services   48,728    44,862    39,872   \n",
      "windows   21,507    24,732    22,488   \n",
      "gaming   15,466    16,230    15,370   \n",
      "linkedin   15,145    13,816    10,289   \n",
      "search and news advertising   12,208    11,591    9,267   \n",
      "enterprise services   7,722    7,407    6,943   \n",
      "devices   5,521    7,306    7,143.\n",
      "\n",
      "Question: what was the revenue in united states versus in other countries in 2023?\n",
      "\n",
      "Answer: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "The total revenue for the United States in 2023 was $106,744 million and the total revenue for other countries was $105,171 million. Therefore, the revenue generated by the United States was slightly higher than that of other countries in 2023.\n"
     ]
    }
   ],
   "source": [
    "query = \"what was the revenue in united states versus in other countries in 2023?\"\n",
    "resp = llm_chain.invoke(\n",
    "    input={\"question\":query,\n",
    "           \"context\": format_docs(query)\n",
    "          }\n",
    ")\n",
    "print(resp['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac365cc8-5e04-4f05-b900-ca44c907d6f3",
   "metadata": {},
   "source": [
    "## Other Queries ideas\n",
    "\n",
    "query = \"what was the expenses for research and development in 2023?\"\n",
    "\n",
    "query = \"what is microsoft 365 consumer count in 2023?\"\n",
    "\n",
    "query = \"what was the revenue generated by windows?\"\n",
    "\n",
    "query = \"what was the main focus for 2023?\"\n",
    "\n",
    "query = \"what's the overall stock information?\"\n",
    "\n",
    "query = \"what sector and companies did microsoft invest in 2023?\"\n",
    "\n",
    "query = \"how many people were laid off by microsoft and what were they offered?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf6a38-1914-4b94-b804-292e03cc148f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
